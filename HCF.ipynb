{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48be914c",
   "metadata": {},
   "source": [
    "# HCF Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d03e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import constraint\n",
    "from techniques.PaDMTP import padmtp_algo\n",
    "from techniques.RandomTesting import random_testing\n",
    "from testcodes.hcf import compute_hcf as hcf\n",
    "from techniques.AdaptiveRandomTesting import adaptive_random_testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a352c5cf",
   "metadata": {},
   "source": [
    "### PaDMTP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ce4885",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = constraint.Problem()\n",
    "\n",
    "problem.addVariable('x', range(1, 16))\n",
    "problem.addVariable('y', range(1, 16))\n",
    "\n",
    "problem.addConstraint(hcf, ['x', 'y'])\n",
    "\n",
    "solutions = problem.getSolutions()\n",
    "\n",
    "length = len(solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f219f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_solutions = []\n",
    "\n",
    "for index, solution in enumerate(solutions):\n",
    "    cleaned_solutions.append(solutions[index])\n",
    "    \n",
    "hcf_length = len(cleaned_solutions)\n",
    "\n",
    "print(\"\\nPossible Solutions Dataset for HCF Code: \\n(x,y) âˆˆ {\", end=\"\")\n",
    "for index, solution in enumerate(cleaned_solutions):\n",
    "    if index == hcf_length - 1:\n",
    "        print(\"({},{})\".format(solution['x'], solution['y']), end=\"\")\n",
    "    else:\n",
    "        print(\"({},{}),\".format(solution['x'], solution['y']), end=\"\")\n",
    "print(\"}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5424a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"HCF - PaDMTP - Test Cases: {hcf_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12c6405",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutPyObj = 'mut.py --target testcodes.hcf --unit-test mutations.test_hcf_padmt -m'\n",
    "\n",
    "padmtp_rslt = padmtp_algo(hcf, cleaned_solutions, mutPyObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b0ce50",
   "metadata": {},
   "outputs": [],
   "source": [
    "padmtp_rslt['PaDMTP_Overhead']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975797a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "padmtp_rslt['PaDMTP_DataFrame']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e41d93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PaDMTP_MT_Scores = []\n",
    "\n",
    "for index, row in padmtp_rslt['PaDMTP_DataFrame'].iterrows():\n",
    "    val = row['MT Score']\n",
    "    val = val.replace(\"%\", \"\")\n",
    "    val = float(val) / 100\n",
    "    val = round(val, 3)\n",
    "    \n",
    "    PaDMTP_MT_Scores.append(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa278379",
   "metadata": {},
   "source": [
    "### Random Testing (RT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66106a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating random inputs\n",
    "rt_test_cases = []\n",
    "for i in range(hcf_length):\n",
    "    x = random.randint(1, 101)\n",
    "    y = random.randint(1, 101)\n",
    "    \n",
    "    rt_test_cases.append((x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cb8575",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"HCF - Random Testing - Test Cases: {len(rt_test_cases)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177e524c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving RT Test Cases to JSON File\n",
    "\n",
    "jsonString = json.dumps(rt_test_cases)\n",
    "jsonFile = open(\"./temp/RT_Test_Cases.json\", 'w')\n",
    "jsonFile.write(jsonString)\n",
    "jsonFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f67843f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pytest_cmd = 'pytest techniques/rt_hcf.py'\n",
    "mutpy_cmd = 'mut.py --target testcodes.hcf --unit-test mutations.test_hcf_rt -m'\n",
    "\n",
    "rt_rslt = random_testing(pytest_cmd, mutpy_cmd, rt_test_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9be891",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_rslt['RT_Overhead']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e396006",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_rslt['RT_DataFrame']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5da4865",
   "metadata": {},
   "outputs": [],
   "source": [
    "RT_MT_Scores = []\n",
    "\n",
    "for index, row in rt_rslt['RT_DataFrame'].iterrows():\n",
    "    val = row['MT Score']\n",
    "    val = val.replace(\"%\", \"\")\n",
    "    val = float(val) / 100\n",
    "    val = round(val, 3)\n",
    "    \n",
    "    RT_MT_Scores.append(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933fd5d7",
   "metadata": {},
   "source": [
    "### Adaptive Random Testing (ART)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a17eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating random inputs\n",
    "art_test_cases = []\n",
    "for i in range(hcf_length):\n",
    "    x = random.randint(-100, 101)\n",
    "    y = random.randint(-100, 101)\n",
    "    \n",
    "    art_test_cases.append([x, y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8ae45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"HCF - Adaptive Random Testing - Test Cases: {len(art_test_cases)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607512db",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutpy_cmd = 'mut.py --target testcodes.hcf --unit-test mutations.test_hcf_art -m'\n",
    "\n",
    "art_rslt = adaptive_random_testing(hcf, mutpy_cmd, art_test_cases, 'HCF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d930202",
   "metadata": {},
   "outputs": [],
   "source": [
    "art_rslt['ART_Overhead']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53e686d",
   "metadata": {},
   "outputs": [],
   "source": [
    "art_rslt['ART_DataFrame']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7aff03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ART_MT_Scores = []\n",
    "\n",
    "for index, row in art_rslt['ART_DataFrame'].iterrows():\n",
    "    val = row['MT Score']\n",
    "    val = val.replace(\"%\", \"\")\n",
    "    val = float(val) / 100\n",
    "    val = round(val, 3)\n",
    "    \n",
    "    ART_MT_Scores.append(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ea71cc",
   "metadata": {},
   "source": [
    "### Pairwise T-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1165549e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import ttest_rel, t\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Data\n",
    "PaDMTP = np.array(PaDMTP_MT_Scores) \n",
    "RT = np.array(RT_MT_Scores)\n",
    "ART = np.array(ART_MT_Scores)\n",
    "\n",
    "# Calculate paired differences\n",
    "differences_PaDMTP_RT = np.subtract(PaDMTP, RT)\n",
    "differences_PaDMTP_ART = np.subtract(PaDMTP, ART)\n",
    "\n",
    "# Perform t-test: PaDMTP vs RT\n",
    "t_statistic_PaDMTP_RT, p_value_PaDMTP_RT = ttest_rel(PaDMTP, RT)\n",
    "t_critical_one_tail_PaDMTP_RT = t.ppf(0.05, len(PaDMTP) - 1)\n",
    "t_critical_two_tail_PaDMTP_RT = t.ppf(0.025, len(PaDMTP) - 1)\n",
    "\n",
    "# Perform t-test: PaDMTP vs ART\n",
    "t_statistic_PaDMTP_ART, p_value_PaDMTP_ART = ttest_rel(PaDMTP, ART)\n",
    "t_critical_one_tail_PaDMTP_ART = t.ppf(0.05, len(PaDMTP) - 1)\n",
    "t_critical_two_tail_PaDMTP_ART = t.ppf(0.025, len(PaDMTP) - 1)\n",
    "\n",
    "# Create the tables\n",
    "table1 = [\n",
    "    [\"Test\", \"Mean\", \"Variance\", \"Observations\", \"df\", \"t Stat\"],\n",
    "    [\"PaDMTP vs RT\", np.mean(differences_PaDMTP_RT), np.var(differences_PaDMTP_RT), len(PaDMTP), len(PaDMTP) - 1, t_statistic_PaDMTP_RT],\n",
    "    [\"PaDMTP vs ART\", np.mean(differences_PaDMTP_ART), np.var(differences_PaDMTP_ART), len(PaDMTP), len(PaDMTP) - 1, t_statistic_PaDMTP_ART]\n",
    "]\n",
    "\n",
    "table2 = [\n",
    "    [\"Test\", \"P(T<=t) one-tail\", \"t Critical one-tail\", \"P(T<=t) two-tail\", \"t Critical two-tail\"],\n",
    "    [\"PaDMTP vs RT\", p_value_PaDMTP_RT / 2, t_critical_one_tail_PaDMTP_RT, p_value_PaDMTP_RT, t_critical_two_tail_PaDMTP_RT],\n",
    "    [\"PaDMTP vs ART\", p_value_PaDMTP_ART / 2, t_critical_one_tail_PaDMTP_ART, p_value_PaDMTP_ART, t_critical_two_tail_PaDMTP_ART]\n",
    "]\n",
    "\n",
    "print(\"<==== HCF Code ====>\")\n",
    "\n",
    "# Print the tables\n",
    "print(\"Table 1:\")\n",
    "print(tabulate(table1, headers=\"firstrow\", tablefmt=\"grid\"))\n",
    "print(\"\\nTable 2:\")\n",
    "print(tabulate(table2, headers=\"firstrow\", tablefmt=\"grid\"))\n",
    "\n",
    "\n",
    "# Perform pairwise t-tests\n",
    "t_stat_RT_PaDMT, p_value_RT_PaDMT = ttest_rel(RT, PaDMTP)\n",
    "t_stat_ART_PaDMT, p_value_ART_PaDMT = ttest_rel(ART, PaDMTP)\n",
    "\n",
    "# Print the t-statistics and p-values\n",
    "print(\"\\n\\nRT vs PaDMT:\")\n",
    "print(\"T-statistic:\", t_stat_RT_PaDMT)\n",
    "print(\"P-value:\", p_value_RT_PaDMT)\n",
    "print(\"\\nART vs PaDMT:\")\n",
    "print(\"T-statistic:\", t_stat_ART_PaDMT)\n",
    "print(\"P-value:\", p_value_ART_PaDMT)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
